==========
References
==========

Datasets
--------

.. [FPB] Malo, P., H. Lu, M. Ahlgren, S. Rönnqvist, and P. Nyberg. (2014). *FinancialPhraseBank-v1.0*. Available at SSRN: https://ssrn.com/abstract=2512146 or http://dx.doi.org/10.2139/ssrn.2512146

.. [FiQA] Sinha, A., Joglekar, M., & Murphy, F. (2018). *FiQA: Financial Opinion Mining and Question Answering*. arXiv preprint arXiv:1809.09431.

.. [TFNS] Araci, D. (2019). *FinBERT: Financial Sentiment Analysis with Pre-trained Language Models*. arXiv preprint arXiv:1908.10063.

.. [NWGI] TheFinAI. (2023). *NWGI: News with GPT Instruction*. Hugging Face Dataset. https://huggingface.co/datasets/TheFinAI/NWGI_test

.. [Headline] FinGPT. (2023). *FinGPT Headline Classification*. Hugging Face Dataset. https://huggingface.co/datasets/FinGPT/fingpt-headline-cls

.. [NER] FinGPT. (2023). *FinGPT Named Entity Recognition*. Hugging Face Dataset. https://huggingface.co/datasets/FinGPT/fingpt-ner-cls

.. [FiNER-139] Loukas, L., Fergadiotis, M., Chalkidis, I., Spyropoulou, E., Malakasiotis, P., Androutsopoulos, I., & Paliouras, G. (2022). *FiNER-139: Financial Numeric Entity Recognition for XBRL Tagging*. Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 4419-4431.

.. [FNXL] Soumya, A., & Joshi, A. (2021). *FNXL: Financial Numerical Expression Labeling*. GitHub Repository. https://github.com/soummyaah/FNXL

.. [XBRL_Term] Han, K., Wang, D., & Zha, D. (2023). *XBRL Terminology*. GitHub Repository. https://github.com/KirkHan0920/XBRL-Agent/blob/main/Datasets/XBRL%20Terminology.xlsx

.. [XBRL_Analysis] Wang, D., Han, K., & Zha, D. (2023). *XBRL Analysis Dataset*. Hugging Face Dataset. https://huggingface.co/datasets/wangd12/XBRL_analysis

.. [Financial_Math] Han, K., Wang, D., & Zha, D. (2023). *Financial Math Formulas*. GitHub Repository. https://github.com/KirkHan0920/XBRL-Agent/blob/main/Datasets/formulas_with_explanations_with_questions_with_gt.xlsx

.. [FinanceBench] Han, K., Wang, D., & Zha, D. (2023). *FinanceBench*. GitHub Repository. https://github.com/KirkHan0920/XBRL-Agent/blob/main/Datasets/financebench.xlsx

Large Language Models
--------------------
.. [BloombergGPT] Wu, S., et al. (2023). *BloombergGPT: A Large Language Model for Finance*. arXiv preprint arXiv:2303.17564.

.. [Llama3] Touvron, H., et al. (2024). *Llama 3: A Family of State-of-the-Art Open Language Models*. Meta AI.

.. [DeepSeekV3] DeepSeek-AI. (2024). *DeepSeek V3: A Powerful Open-Source Language Model*. DeepSeek AI.

.. [GPT4o] OpenAI. (2024). *GPT-4o: Advancing Multimodal Understanding*. OpenAI.

.. [Gemini2] Google. (2024). *Gemini 2.0: A Family of Highly Capable Multimodal Models*. Google AI.

LoRA Methods
-----------

.. [LoRA] Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., ... & Chen, W. (2022). *LoRA: Low-rank adaptation of large language models*. International Conference on Learning Representations (ICLR).

.. [QLoRA] Dettmers, T., Pagnoni, A., Holtzman, A., & Zettlemoyer, L. (2023). *QLoRA: Efficient finetuning of quantized LLMs*. Advances in Neural Information Processing Systems, 36, 10088-10115.

.. [DoRA] Liu, S. Y., Wang, C. Y., Yin, H., Molchanov, P., Wang, Y. C. F., Cheng, K. T., & Chen, M. H. (2024). *DoRA: Weight-decomposed low-rank adaptation*. Forty-first International Conference on Machine Learning.

.. [RSLoRA] Kalajdzievski, D. (2023). *Rank-stabilized scaling factor for LoRA adaptation*. arXiv preprint.

.. [FedLoRA] Liu, X. Y., Zhu, R., Zha, D., Gao, J., Zhong, S., White, M., & Qiu, M. (2025). *Differentially private low-rank adaptation of large language model using federated learning*. ACM Transactions on Management Information Systems, 16(2), 1-24.

.. [Sun2024] Youbang Sun, Zitao Li, Yaliang Li, and Bolin Ding. Improving loRA in privacy-preserving federated learning. In The Twelfth International Conference on Learning Representations, 2024.

Other Papers
-----------

.. [BERTScore] Zhang, T., Kishore, V., Wu, F., Weinberger, K. Q., & Artzi, Y. (2019). *BERTScore: Evaluating Text Generation with BERT*. arXiv preprint arXiv:1904.09675.

.. [FinLoRA] Wang, D., Patel, J., Zha, D., Yang, S. Y., & Liu, X. Y. (2025). *FinLoRA: Benchmarking LoRA Methods for Fine-Tuning LLMs on Financial Datasets*. arXiv preprint arXiv:2505.19819.

.. [Liu2022] Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, and Colin A Raffel. Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning. Advances in Neural Information Processing Systems, 35:1950–1965, 2022.

.. [Liu2024] Jiayu Liu, Zhenya Huang, Tong Xiao, Jing Sha, Jinze Wu, Qi Liu, Shijin Wang, and Enhong Chen. SocraticLM: Exploring socratic personalized teaching with large language models. In The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024.]

.. [Xie2024] Qianqian Xie, Weiguang Han, Zhengyu Chen, et al. FinBen: An holistic financial benchmark for large language models. In The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2024.

