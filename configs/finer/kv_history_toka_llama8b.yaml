## FinLoRA Finer â€” HistoryAgent with cartridges on local

runtime:
  max_envs_to_visit: 1000
  max_steps_per_episode: 1
  scores_path: scores.jsonl
  run_validation_at_start: true
  validation_num_workers: 200
  validation_freq: 40
  checkpoint_dir: checkpoints
  checkpoint_every_episodes: 50
  checkpoint_strategy: last_n
  checkpoint_keep_last: 40
  checkpoint_on_start: false
  start_episode_index: 250
  # resume_from: "/scratch/m000122/stalaei/logs/continual_learning/outputs/finer/history_agent/brad_magic_with_progressive_fewshots/20251020_111212/checkpoints/ep_000250"

train_dataset:
  type: finer
  hf_dataset: stalaei/finer_v1
  split: train_ICL
  input_field: context
  target_field: target
  instruction_template: null
  max_samples: 2000
  shuffle: false

validation_dataset:
  type: finer
  hf_dataset: stalaei/finer_v1
  split: val
  input_field: context
  target_field: target
  instruction_template: null
  max_samples: 1000
  shuffle: false

agent:
  type: history_agent
  lm_config:
    model: toka:meta-llama/Llama-3.1-8B-Instruct
    train_temperature: 0.3
    val_temperature: 0.0
    max_output_tokens: 2048
    log_calls: true
    base_url: "http://localhost:8096"
    stop_sequences: [FEEDBACK, OBSERVATION]
    max_retries: 3
    top_logprobs: 20
  memory_config:            # primary history memory
    _type: history_list
    max_length: null
  cartridges:
    - id: oct22_250train_256tokens_sysmem_tokensupervision-cache-step1300
      source: local
      force_redownload: false
  history_k: null
  system_prompt: "{file:src/data/prompts/finer/system_prompt_brad_magic.txt}"

output:
  results_dir: outputs/finer/history_agent/oct22_250train_256tokens_sysmem_tokensupervision-cache-step1300
  log_level: INFO
