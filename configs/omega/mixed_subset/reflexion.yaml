## OMEGA (allenai/omega-explorative) â€” ReflexionAgent
## Demonstrates self-reflection on mathematical reasoning tasks

runtime:
  max_envs_to_visit: 120
  max_steps_per_episode: 1
  scores_path: scores.jsonl
  run_validation_at_start: true
  validation_num_workers: 100
  validation_freq: 10

train_dataset:
  hf_dataset: "stalaei/omega-explorative-mixed-subset"
  split: "train"
  input_field: "messages"
  target_field: "ground_truth"
  instruction_template: null
  max_samples: 120
  shuffle: false
  eval_mode: numeric_tol
  eval_tolerance: 1e-6
  expect_boxed: true

validation_dataset:
  hf_dataset: "stalaei/omega-explorative-mixed-subset"
  split: "val"
  input_field: "messages"
  target_field: "ground_truth"
  instruction_template: null
  max_samples: 200
  shuffle: false
  eval_mode: numeric_tol
  eval_tolerance: 1e-6
  expect_boxed: true

agent:
  type: reflexion_agent
  
  # LM configuration
  lm_config:
    model: "gemini-2.0-flash" #"gemini-2.5-flash"
    temperature: 0.0
    max_output_tokens: 8192 #65536
    log_calls: true
  
  # Memory configuration
  memory_config:
    _type: history_list
    max_length: 2000
  
  # History configuration
  history_k: null  # null = use all history items
  
  # Reflexion-specific configuration
  enable_reflection: true
  reflect_on_failure_only: true  # Only reflect on incorrect answers
  failure_threshold: 1.0  # Score < 1.0 means incorrect
  max_reflections_in_prompt: 10  # Show last 10 reflections
  
  # Custom system prompt for math domain
  agent_system_prompt: "You are a careful math assistant. Learn from your past mistakes by reviewing your reflections and prior experience when solving new problems. Pay attention to the patterns in your errors and adjust your approach accordingly."
  
  # Use default reflection prompts (task-agnostic)
  reflection_system_prompt: null
  reflection_few_shot_examples: null
  
  # Base agent settings
  verbose: true

output:
  results_dir: outputs/omega_mixed_subset/explorative_reflexion_agent/8k_flash_2.0
  log_level: INFO

